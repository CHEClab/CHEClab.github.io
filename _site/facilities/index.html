<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <!-- Favicon -->
  <link rel="shortcut icon" href="/favicon.ico"> 

  <!-- Font -->
  <link href="https://fonts.googleapis.com/css2?family=Open+Sans:wght@400;600&display=swap" rel="stylesheet">

  <link rel="stylesheet" href="/assets/styles/stylesheets/bootstrap.min.css">
  <link rel="stylesheet" href="/assets/styles/stylesheets/style.css">
  <link rel="icon" href="/assets/favicon.ico">
  <script src="/assets/libs/holderjs/holder.js"></script></head><body><header>
  <div class="d-flex flex-column flex-md-row align-items-center p-3 px-md-4 mb-3 bg-white border-bottom box-shadow">
      <a href="/" class="my-0 mr-md-auto font-weight-normal">
          <img src="/assets/images/logo.png" alt="" style="height:40px;">
      </a>
      <nav class="my-2 my-md-0 mr-md-3">
        
              
              <a class="p-2 text-dark" href="/">Home</a>  
              
              <a class="p-2 text-dark" href="/members/">Members</a>  
              
              <a class="p-2 text-dark" href="/news/">News</a>  
              
              <a class="p-2 text-dark" href="/publications/">Publications</a>  
              
              <a class="p-2 text-dark" href="https://www.flickr.com/photos/123468034@N06/albums">Photos</a>  
              
      </nav>
  </div>
</header><main class="page-content" aria-label="Content">
      <div class="wrapper">
        <main>
    <div class="container">
        <div class="col-xl-12">
            <h2 id="facilities">Facilities</h2>

<table>
  <thead>
    <tr>
      <th>Schedule</th>
      <th>Item</th>
      <th>Introduction</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><img src="https://farm1.staticflickr.com/908/40440710080_3a80d41776.jpg" alt="Our Lab" /></td>
      <td>Our lab</td>
      <td>Our lab has many HCI facilities, like VICON (12 Bonita-10 cameras for motion capture); Dikablis (Provide synchronous eye tracking with the Vicon system), Epson Moverio (Tool for Augmented reality), Occulus Rift Development Kit 2 (Tool for Virtual reality), Virtuax Omni (Serves as a “treadmill” during virtual environment activity), Procomp Infiniti 8 channel + electrodes (A tool for measuring participant’s physiological responses during interaction), Multitouch display ((NEC MultiSync P801 PG, 80 inch) + Touch Overlay + OPS-PCAF-WS Computer), PHANTOM Premium 1.5 (Simulate haptic interaction), Sony 3D Projector (VPL-VW 1100ES, 3D interactive display), and Tobii (Eye-tracking system).</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/954/40440711030_bcc291974a.jpg" alt="HTC VIVE" /></td>
      <td>HTC VIVE</td>
      <td>The HTC Vive is a virtual reality headset developed by HTC and Valve Corporation. The headset uses “room scale” tracking technology, allowing the user to move in 3D space and use motion-tracked handheld controllers to interact with the environment.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/954/40440708320_61a0b29189.jpg" alt="VICON (12 cameras)" /></td>
      <td>VICON (12 cameras)</td>
      <td>Vicon is the leading developer of motion capture products and services for the Life Science, Entertainment and Engineering industries. Motion capture (mocap) is the process of recording the movement of objects or people. In motion capture sessions, movements of one or more actors are sampled many times per second. Whereas early techniques used images from multiple cameras to calculate 3D positions, often the purpose of motion capture is to record only the movements of the actor, not his or her visual appearance. This animation data is mapped to a 3D model so that the model performs the same actions as the actor.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/973/42201545542_c3df5d22df.jpg" alt="Dikablis Eye Tracker" /></td>
      <td>Dikablis Eye Tracker</td>
      <td>Dikablis Glasses combine binocular eye tracking with high measuring accuracy and standardized parameter calculation – ideal for the synchronous measurement of gaze data from several subjects in real-time. The highly ergonomic design ensures a perfect fit and minimizes visual obscuration. They are built to suit any head size and also fit over glasses. Dikablis Essential Glasses are connected directly to the recording computer. Cable Box, video grabber, all necessary cables and power supply are always included. Dikablis Essential is shipped in a transport case which covers all equipment. Dikablis Essential Glasses can be easily worn over normal eyeglasses as well as shutter, polarized and many virtual reality glasses. The slim design ensures a perfect fit and minimizes visual obscuration. It‘s light weight makes Dikablis Essential Glasses ideal for longer studies.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/824/42201542592_9f4de3b7a9.jpg" alt="Phantom Premium 1.5" /></td>
      <td>Phantom Premium 1.5</td>
      <td>The Phantom Premium 1.5/6DOF haptic device provides the largest workspaces and highest forces while offering a broad range of force feedback workspaces, various ranges of motion and varying stiffness. Phantom Premium offers six degrees of freedom (3 translational, 3 torque) in output capabilities. This device includes a passive stylus and thimble gimbal and provides 3 degrees of freedom positional sensing and 3 degrees of freedom force-feedback. This device can provide force feedback include virtual assembly, virtual prototyping, maintenance path planning, teleoperation, and molecular modeling. Simulating torque force feedback makes it possible to feel the collision and reaction forces and torques of a part in a virtual assembly path, or the rotational torques supported by a remote “slave” robot in a teleoperation environment.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/982/42201544662_8546755c35_m.jpg" alt="Multi-TouchG³Plus" /></td>
      <td>Multi-Touch G³ Plus</td>
      <td>Multi-Touch G³ Plus is a touch screen overlay that can be easily mounted onto any LCD or Plasma TV monitors.          This simple, lightweight and low cost solution lets you deploy Multi-Touch technology instantly to existing monitors without the need of any configuration. Multi-Touch G² Plus is connected to the computer via a USB cable.          The Multi-Touch G³ Plus is new generation touch screen overlay with 32 touch points, which can be easily mounted onto most LCD or Plasma TV monitors. we provide an easy and reliable multi-touch solution to help deploy Multi-Touch technology instantly to existing monitors without any configuration.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/912/40440710420_c3bd3318ea.jpg" alt="Oculus" /></td>
      <td>Oculus</td>
      <td>The Oculus Rift is one of the first consumer-targeted virtual reality headsets. It has a resolution of 1080×1200 per eye, a 90 Hz refresh rate, and a wide field of view. It has integrated headphones which provide a 3D audio effect. The Rift has rotational and positional tracking.              The positional tracking is performed by a USB stationary IR sensor, which normally sits on the user’s desk, allowing for using the Rift while sitting, standing, or walking around the same room. DK2 is the latest development kit for Rift that allows developers to build amazing games and experiences.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/963/42201545392_b48b985d44_o.jpg" alt="Emotiv EEG (EEG, Epoc+)" /></td>
      <td>Emotiv EEG (EEG, Epoc+)</td>
      <td>Electroencephalography (EEG) is an electrophysiological monitoring method to record electrical activity of the brain. It is typically noninvasive, with the electrodes placed along the scalp, although invasive electrodes are sometimes used in specific applications. EEG measures voltage fluctuations resulting from ionic current within the neurons of the brain In clinical contexts, EEG refers to the recording of the brain’s spontaneous electrical activity over a period of time, as recorded from multiple electrodes placed on the scalp. Diagnostic applications generally focus on the spectral content of EEG, that is, the type of neural oscillations (popularly called “brain waves”) that can be observed in EEG signals.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/947/40440711100_62bed33ef8_o.jpg" alt="EPSON Moverio" /></td>
      <td>EPSON Moverio</td>
      <td>Enhance Your World with a New Standard in WearableTechnology. Get ready for the next generation of augmented reality platforms -the BT-200 from Epson, the world leader in projection technology. Thesebinocular, transparent smart glasses open up a whole new world inentertainment, manufacturing, medical science and more. Unlike competitivemodels, each lens has its own display, right in your field of vision, projectedinto your surroundings. And, the BT-200 boasts 2x the virtual screen size, at aremarkably affordable price. These lightweight glasses work out-of-the-box withBluetooth and other technology, plus most Android apps. With a front-facingcamera and motion tracker, the BT-200 is a premier development platform forapps of the future and hands-free scenarios, delivering large, 2D or 3D images,front and center - virtually anywhere.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/947/42201545032_2ea66800ee_o.jpg" alt="Leap Motion Camera" /></td>
      <td>Leap Motion Camera</td>
      <td>The Leap Motion controller is a small USB peripheral device which isdesigned to be placed on a physical desktop, facing upward. Using twomonochromatic IR cameras and three infrared LEDs, the device observes a roughlyhemispherical area, to a distance of about 1 meter. The LEDs generatepattern-less IR light and the cameras generate almost 300 frames per second ofreflected data, which is then sent through a USB cable to the host computer,where it is analyzed by the Leap Motion controller software using “complexmaths” in a way that has not been disclosed by the company, in some waysynthesizing 3D position data by comparing the 2D frames generated by the twocameras.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/946/42201542302_2c79fd87a5_o.jpg" alt="Tobii: Eye Tracking System" /></td>
      <td>Tobii: Eye Tracking System</td>
      <td>Tobii EyeX enables new functions that revolutionize our daily computer interaction. It enhances the experience for any laptop with a touchpad enabling users to point with their eyes naturally and intuitively.              Users can then avoid cumbersome and unnecessary movement of having to reach for their mouse or drag a finger several times on a touchpad to move the mouse cursor to where he or she is already looking. This caters for a much more natural and intuitive interaction with the device. People can now “touch where you look”.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/824/42201545332_9b003503f3_o.jpg" alt="Eye PlusPlus" /></td>
      <td>Eye PlusPlus</td>
      <td>AuxDeco is a walk assistance tool for the visually impaired whom TokyoUniversity and Eye PlusPlus Co. developed jointly. You can feel on forehead awhite line and a pedestrian crossing pulled in the continuing movement, groundsuch as a thing in the distance, a person or the car as if you totally see themby “AuxDeco”. It can get safety and enjoyment of walking, whose informationcouldn’t get by using the white walking cane.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/906/42201544842_abd73f7ffe_o.jpg" alt="Microsoft Kinect" /></td>
      <td>Microsoft Kinect</td>
      <td>Kinect is a line of motion sensing input devices by Microsoft for Xbox 360 and Xbox One video game consoles and Windows PCs. Based around a webcam-style add-on peripheral, it enables users to control and interact with their console/computer without the need for a game controller, through a natural user interface using gestures and spoken commands.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/967/40440708210_de21c04af6_o.jpg" alt="Wacom Cintiq 21UX" /></td>
      <td>Wacom Cintiq 21UX</td>
      <td>The newly-redesigned Cintiq 21UX incorporates Wacom’s most advanced pen technology in a sleek, black, display, allowing photographers, designers, animators and other creative professionals to work naturally and intuitively directly on the surface of the large-format, 21.3” LCD screen. The Cintiq 21UX now detects 2048 levels of pressure, giving you even more control over pressure-sensitive pen effects such as line weight, opacity, and exposure. With Wacom’s new Tip Sensor, the pen now features a lower activation force that captures even the most subtle nuances of pressure. The ambidextrous design features rear-mounted Touch Strips, along with the accompanying Touch Strip Toggle Buttons, which give you control of up to four application-specific Touch Strip functions like brush size, zooming, canvas rotation and scrolling.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/912/40440711410_ec03f73412_o.jpg" alt="Arduino Robot" /></td>
      <td>Arduino Robot</td>
      <td>The Arduino Robot is the first official Arduino on wheels. The robot has two processors, one on each of its two boards. The Motor Board controls the motors, and the Control Board reads sensors and decides how to operate. Each of the boards is a full Arduino board programmable using the Arduino IDE. The Robot has many of its pins mapped to on-board sensors and actuators.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/908/42201542672_74a793f166_o.jpg" alt="Phantom Omni" /></td>
      <td>Phantom Omni</td>
      <td>The Phantom Omni is a mid-range professional haptic device. It provides 6 degrees of freedom positional sensing and 3 degrees of freedom force-feedback. Phantom Omni is a motorized device that applies force feedback on the user’s hand, allowing them to feel virtual objects and producing true-to-life touch sensations as user manipulates on-screen 3D objects.                 Phantom Omni can be used in diverse applications, including: simulation, training, skills assessment, rehearsal, virtual assembly, robotic control, collision detection, machine interface design, rehabilitation, mapping and dozens of other applications.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/955/40440711910_2e2e185d30_o.jpg" alt="Arduino (Uno, Mega, Micro, Esplora)" /></td>
      <td>Arduino (Uno, Mega, Micro, Esplora)</td>
      <td>Arduino is an open-source prototyping platform based on easy-to-use hardware and software. Arduino boards are able to read inputs - light on a sensor, a finger on a button, or a Twitter message - and turn it into an output - activating a motor, turning on an LED, publishing something online. You can tell your board what to do by sending a set of instructions to the microcontroller on the board.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/824/42201542492_eb0e938a95_o.jpg" alt="See-through" /></td>
      <td>See-through</td>
      <td>A see-through display is an electronic display that allows the user to see what is shown on the glass screen while still being able to see through it. It is a technology that has been around for a decade or two, but only as of 2012 was it being incorporated by companies such as Samsung, Planar Systems, and taptl into consumer products like handheld devices, televisions, and other technology as well as building materials such as glass. These screens can be used for augmented reality, a way of enhancing your view of the world with digital images overlaid onto real ones, and other applications such as shopping displays and more sophisticated computer screens.</td>
    </tr>
    <tr>
      <td><img src="https://farm1.staticflickr.com/910/40440710440_b79cb1f487_o.jpg" alt="Self-made Multitouch Systemh" /></td>
      <td>Self-made Multitouch System</td>
      <td>Our Multitouch system is based on frustrated total internal reflection (FTIR), a phenomenon familiar to both the biometric and robot sensing communities. It acquires true touch image information at high spatial and temporal resolutions, is scalable to large installations, and is well suited for use with rear-projection. It aims to make the technology readily available to those who wish to explore the multi-touch interaction techniques that this system enables.</td>
    </tr>
  </tbody>
</table>

        </div>
    </div>
</main>
<script>
document.addEventListener('DOMContentLoaded', function() {
    // 获取所有表格
    const tables = document.getElementsByTagName('table');

    // 遍历每个表格
    for(let table of tables) {
        // 添加Bootstrap表格类
        table.classList.add('table');
        
        
        // 获取所有行
        const rows = table.getElementsByTagName('tr');
        
        // 遍历每一行
        for(let row of rows) {
            // 设置行样式
            row.style.borderBottom = '1px solid #ddd';
            
            // 获取第一列单元格
            const firstCell = row.cells[0];
            if(firstCell) {
                // 获取单元格中的图片
                const img = firstCell.querySelector('img');
                if(img) {
                    // 设置图片最大宽度为300px
                    img.style.maxWidth = '300px';
                }
            }
        }
    }
});
</script>

      </div>
    </main><div class="container">
<footer class="pt-4 my-md-5 pt-md-5 border-top">
    <div class="row">
        <div class="col-4 col-md">

            <h5>Events</h5>
            <ul class="list-unstyled text-small">
                <li>
                    <a class="text-muted disabled" href="http://iw2021.xrenlab.com" target="_blank">IWHEC 2021</a>
                </li>
                <li>
                    <a class="text-muted disabled" href="http://iw2020.xrenlab.com" target="_blank">IWHEC 2020</a>
                </li>
                <li>
                    <a class="text-muted disabled" href="http://iw2019.xrenlab.com" target="_blank">IWHEC 2019</a>
                </li>
                <li>
                    <a class="text-muted disabled" href="http://iss2018ws.xrenlab.com" target="_blank">ISS Workshop 2018</a>
                </li>
                <li>
                    <a class="text-muted disabled" href="https://chec2020class.github.io/" target="_blank">CHEC Cloud Talk Series</a>
                </li>
            </ul>

        </div>
        <div class="col-4 col-md">
            <h5></h5> <br />
            <ul class="list-unstyled text-small">
                <li>
                    <a class="text-muted disabled" href="https://ixap2018.github.io/" target="_blank">IxAP 2018</a>
                </li>
                <li>
                    <a class="text-muted disabled" href="http://forum.chec.ren" target="_blank">IWHEC 2017</a>
                </li>
                <li>
                    <a class="text-muted disabled" href="http://itap2016.xrenlab.com" target="_blank">ITAP 2016</a>
                </li>
                <li>
                    <a class="text-muted disabled" href="http://idhf2016.xrenlab.com" target="_blank">IDHF 2016</a>
                </li>
            </ul>
        </div>
        <div class="col-4 col-md">
            <h5>About</h5>
            <ul class="list-unstyled text-small">
                <li>
                    <a class="text-muted disabled" href="https://www.kochi-tech.ac.jp/english/admission/ssp_aft19oct/ssp_application_guideline.html" target="_blank">KUT SSP</a>
                </li>
                 <li>
                    <a class="text-muted disabled" href="" target="_blank">KUT CSC</a>
                </li>
            </ul>
        </div>
        <div class="w-100"></div>
        <div class="col-12 col-md">
            <small class="d-block mb-3 text-muted">Center for Human-Engaged Computing, Kochi University of Technology, Tosayamada, Kami City, Kochi,  JAPAN P: +81-887-57-2087 © 2023 All Rights Reserved.
        </div>
    </div>
</footer>
</div><script src="/assets/scripts/popper.js"></script>
<script src="/assets/scripts/jquery.min.js"></script>
<script src="/assets/scripts/bootstrap.min.js"></script></body>

</html>
